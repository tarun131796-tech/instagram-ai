import os
from typing import Any

# IMPORTANT:
# Do NOT instantiate any LLM at import time.
# Everything must happen lazily inside get_llm().

try:
    from langchain_google_genai import ChatGoogleGenerativeAI
except Exception:
    ChatGoogleGenerativeAI = None


class SafeMockLLM:
    """
    Fallback LLM used when GOOGLE_API_KEY / GEMINI_API_KEY is missing.
    This guarantees the pipeline NEVER crashes.
    """

    def invoke(self, prompt: Any):
        class Response:
            content = (
                "### POST\n"
                "Post Type: Reel\n\n"
                "### CAPTION\n"
                "Hook: Sample hook for automation\n"
                "Full caption: Sample caption body generated by SafeMockLLM.\n"
                "CTA: Sample CTA\n\n"
                "### HASHTAGS\n"
                "#automation #mock #test\n\n"
                "### VISUAL_ASSETS\n"
                "#### REEL_SCENES\n"
                "Scene Number: 1\n"
                "Duration: 3s\n"
                "Image Prompt: Indian millennial person using skincare product, natural daylight, realistic\n"
                "On-screen Text: Sample overlay text\n"
                "Transition: Cut\n"
            )

        print("⚠️ Using SafeMockLLM (no Gemini API key found)")
        return Response()


def get_llm():
    """
    Factory method.
    This function is the ONLY place where an LLM is created.
    """

    api_key = os.getenv("GOOGLE_API_KEY") or os.getenv("GEMINI_API_KEY")

    if api_key and ChatGoogleGenerativeAI:
        print("✅ Using Gemini 2.5 Flash")
        return ChatGoogleGenerativeAI(
            model="gemini-2.5-flash",
            temperature=0.7,
            google_api_key=api_key,
        )

    # ---- Guaranteed fallback ----
    return SafeMockLLM()
